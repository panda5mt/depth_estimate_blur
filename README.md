# depth_estimate_blur
## Defocusによる画像ボケを利用した深度推定  
TIER IV C1カメラのレビューをしていたところ、光学的に良好な特性を持つカメラであることがわかった。ここにテスト用コードとともに、良好な特性結果をここに簡易にまとめた。

組み込み向けCPUなど処理能力やメモリといったリソースが比較的少ないデバイスでのコンピュータビジョンにも利用できそうである。
(組み込み機器にGMSL2インターフェースがあのるかという議論はまた別であるし、USB変換も可能であるのでここでは取り上げない)

ここでは
- コードの動かし方について
- 調整方法
- C1カメラについて
- Defocus blurを利用した深度推定の技術的背景について
- 結論

を順に取り上げる。






## コード
ここからはすべてTIER IV C1カメラで撮像した映像を前提とする。他の撮像デバイスから取得した映像は、ここにあげたコードでの動作は推奨されない。

1. 静止画での深度推定

    [main.m](./main.m)をMATLAB/MATLAB onlineで実行する．

    下記Figureが出現する．
    ![](img/scr1.png)
    カラーマップは赤色になるほどカメラに近く、水色ほど遠ざかる。(物体は焦点距離よりもカメラから遠ざかっているものとする)

2. 動画での深度推定
    
    間違い探しの画像は[Wikipedia](https://en.wikipedia.org/wiki/Spot_the_difference)からの引用である．
    [hlac_main2.m](./hlac_main2.m)をMATLAB/MATLAB onlineで実行する．

    下記グラフが出現する．
    
    ![](img/scr2.png)
    上記グラフは間違い探し画像のReferenceおよびTargetのHLAC特徴量と差分，また，その内積を求めた際の位相差である．位相差が大きい(=間違い探しの答えである確率が大きい)所を，右図に示した．
## TIER IV C1カメラとは
[自動運転&モビリティ向け車載HDRカメラ](https://www.paltek.co.jp/solution/tier4/index.html)
で、
## 映像を撮影、録画した環境について
GMSL2ｰUSB3変換を経由し、
## 深度推定基本
### Defocus Blurについて
### Thin Lens Modelの必要性
Gaussian Filterにきんじできる。
### HDRである必要について

## このリポジトリ内のコードのアドバンテージ 
### 高速化

## 結論 
チューニングされたThin lens modelに従う複合レンズと、HDRイメージセンサを搭載したC1カメラを簡易評価した。屋内、屋外ともに深度推定が可能であることを示した。

ADASも含め、ロボティクス方面でカメラを利用したり、工場内移動ロボット(群ロボ)などコンピュータリソースが潤沢にない環境で画像処理をする分野で威力を発揮するものと思われる。
